{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpaavfkxjn4I"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVvdJhktjn4N"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XH64024jn4O"
      },
      "source": [
        "**Read our [blog post](https://unsloth.ai/blog/r1-reasoning) for guidance on how to train reasoning models.**\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcPI_Fhrjn4O"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZmVkatYxjn4P"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Normally using pip install unsloth is enough\n",
        "\n",
        "# Temporarily as of Jan 31st 2025, Colab has some issues with Pytorch\n",
        "# Using pip install unsloth will take 3 minutes, whilst the below takes <1 minute:\n",
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
        "!pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "!pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQZ7n7kGjn4Q"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "ecdb1165-d4e1-4026-e535-030f14fe3917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.48.3.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6bZsfBuZDeCL",
        "outputId": "113c510e-c08e-46f0-cfbc-1a2e0e16d470",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.2.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the Glaive Function Calling dataset from [madroid](https://huggingface.co/datasets/madroid/glaive-function-calling-openai), which is a version of the original [Glaive Function Calling v2](https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2) pre-processed to facilitate integration. You can replace this code section with your own data prep.\n",
        "\n",
        "**[NOTE]** Each model has its own Tool Calling template. For `llama-3.1` we'll use the [user defined custom tools](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/#user-defined-custom-tool-calling) template. If you want to use another model and/or template, you'll need to write your own data prep.\n",
        "\n",
        "**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n",
        "\n",
        "**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n",
        "\n",
        "If you want to use the `llama-3` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n",
        "\n",
        "For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define system prompt and message delimiters\n",
        "system_prompt = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "\n",
        "Environment: ipython\n",
        "Cutting Knowledge Date: December 2023\n",
        "Today Date: 23 July 2024\n",
        "\n",
        "# Tool Instructions\n",
        "- Always execute python code in messages that you share.\n",
        "- When looking for real time information use relevant functions if available else let the user know\n",
        "\n",
        "\n",
        "\n",
        "You have access to the following functions:\n",
        "\n",
        "{functions}\n",
        "\n",
        "\n",
        "If a you choose to call a function ONLY reply in the following format:\n",
        "<{{start_tag}}={{function_name}}>{{parameters}}{{end_tag}}\n",
        "where\n",
        "\n",
        "start_tag => `<function`\n",
        "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
        "end_tag => `</function>`\n",
        "\n",
        "Here is an example,\n",
        "<function=example_function_name>{{\"example_name\": \"example_value\"}}</function>\n",
        "\n",
        "Reminder:\n",
        "- Function calls MUST follow the specified format\n",
        "- Required parameters MUST be specified\n",
        "- Only call one function at a time\n",
        "- Put the entire function call reply on one line\n",
        "- Always add your sources when using search results to answer the user query\n",
        "\n",
        "You are a helpful assistant.<|eot_id|>\"\"\"\n",
        "\n",
        "user_message = \"<|start_header_id|>user<|end_header_id|>\\n\\n{}<|eot_id|>\"\n",
        "assistant_message = \"<|start_header_id|>assistant<|end_header_id|>                      \\n\\n{}<|eot_id|>\"\n",
        "assistant_tool_message = \"<|start_header_id|>assistant<|end_header_id|>                      \\n\\n{}<|eom_id|>\"\n",
        "tool_response_message = \"<|start_header_id|>ipython<|end_header_id|>\\n\\n{}<|eot_id|>\"\n",
        "assistant_continuation_prefix = \"<|start_header_id|>assistant<|end_header_id|>                      \"\n",
        "assistant_continuation_message = \"<|start_header_id|>assistant<|end_header_id|>                      \\n\\n{}<|eot_id|>\"\n",
        "function_string_template = \"\"\"Use the function '{name}' to: {description}\\n{schema}\"\"\""
      ],
      "metadata": {
        "id": "Vw8Ib-_zU9Eq",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Util processing functions\n",
        "import ast, json\n",
        "\n",
        "def convert_tool_format(tool):\n",
        "    func = tool.get(\"function\", {})\n",
        "    name = func.get(\"name\", \"\")\n",
        "    description = func.get(\"description\", \"\")\n",
        "    parameters_a = func.get(\"parameters\", {})\n",
        "    properties = parameters_a.get(\"properties\", {})\n",
        "    required_params = parameters_a.get(\"required\", [])\n",
        "    def map_type(a_type, a_format=None):\n",
        "        if a_type == \"string\":\n",
        "            return \"string\"\n",
        "        elif a_type == \"number\":\n",
        "            return \"int\"\n",
        "        elif a_type == \"boolean\":\n",
        "            return \"bool\"\n",
        "        return a_type\n",
        "    parameters_b = {}\n",
        "    for param, details in properties.items():\n",
        "        parameters_b[param] = {\n",
        "            \"param_type\": map_type(details.get(\"type\"), details.get(\"format\")),\n",
        "            \"description\": details.get(\"description\", \"\"),\n",
        "            \"required\": param in required_params\n",
        "        }\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"description\": description,\n",
        "        \"parameters\": parameters_b\n",
        "    }\n",
        "\n",
        "def get_function_string(f):\n",
        "    converted_tool = convert_tool_format(f)\n",
        "    return function_string_template.format(\n",
        "        name=converted_tool[\"name\"],\n",
        "        description=converted_tool[\"description\"],\n",
        "        schema=json.dumps(converted_tool)\n",
        "    )\n",
        "\n",
        "def convert_function_call_format(call):\n",
        "    func_data = call.get(\"function\", {})\n",
        "    func_name = func_data.get(\"name\", \"\")\n",
        "    arguments_str = func_data.get(\"arguments\", \"{}\")\n",
        "    try:\n",
        "        arguments_dict = ast.literal_eval(arguments_str)\n",
        "    except Exception:\n",
        "        arguments_dict = {}\n",
        "    arguments_json = json.dumps(arguments_dict)\n",
        "    return f\"<function={func_name}>{arguments_json}</function>\"\n",
        "\n",
        "def process_block(block):\n",
        "    tool_index = None\n",
        "    for i, msg in enumerate(block):\n",
        "        if msg[\"role\"] == \"assistant\" and \"tool_calls\" in msg:\n",
        "            tool_index = i\n",
        "            break\n",
        "    filtered_block = []\n",
        "    if tool_index is not None:\n",
        "        for i, msg in enumerate(block):\n",
        "            if msg[\"role\"] == \"assistant\" and i < tool_index:\n",
        "                continue\n",
        "            filtered_block.append(msg)\n",
        "    else:\n",
        "        filtered_block = block\n",
        "    block_context = \"\"\n",
        "    tool_called = False\n",
        "    for msg in filtered_block:\n",
        "        if msg[\"role\"] == \"assistant\":\n",
        "            if \"tool_calls\" in msg:\n",
        "                block_context += assistant_tool_message.format(convert_function_call_format(msg[\"tool_calls\"][0]))\n",
        "            else:\n",
        "                if tool_called:\n",
        "                    block_context += assistant_continuation_message.format(msg[\"content\"])\n",
        "                    tool_called = False\n",
        "                else:\n",
        "                    block_context += assistant_message.format(msg[\"content\"])\n",
        "        elif msg[\"role\"] == \"tool\":\n",
        "            block_context += tool_response_message.format(msg[\"content\"])\n",
        "            tool_called = True\n",
        "    return block_context\n",
        "\n",
        "def get_formatted_sample(sample):\n",
        "    functions_string = \"\\n\\n\".join([get_function_string(f) for f in sample.get(\"tools\", [])])\n",
        "    context = system_prompt.format(functions=functions_string)\n",
        "    block = []\n",
        "    for message in sample[\"messages\"]:\n",
        "        if message[\"role\"] == \"system\":\n",
        "            continue\n",
        "        elif message[\"role\"] == \"user\":\n",
        "            if block:\n",
        "                context += process_block(block)\n",
        "                block = []\n",
        "            context += user_message.format(message[\"content\"])\n",
        "        else:\n",
        "            block.append(message)\n",
        "    if block:\n",
        "        context += process_block(block)\n",
        "    return context\n"
      ],
      "metadata": {
        "id": "8vdlWCEoVAN2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LjY75GoYUCB8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a260c69c1bc24faaba45c4d96f6ea2f6",
            "3ed1d73212784ebf81c2496cff7e1f2a",
            "53565e6b78004ef9b447121f84985bb7",
            "86edadf55c99416e911ad55d52494038",
            "819ba37f02e549b3bd4b3b7b87f56d1f",
            "ea72b5a4fcc54096870d16e6ecb0ca3a",
            "7f7aeb38c44a4732af38180fcfb1da6c",
            "c607cb289d05404386be3c5c87d83836",
            "a5f08b69b7e4432e9d983ac974e09b38",
            "9b727b7e5455450d94724eec947e3004",
            "848e8392e481410badcdccd57d13dee7"
          ]
        },
        "outputId": "0555f238-be41-4bbf-b0d6-3e94ea231cc9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/112754 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a260c69c1bc24faaba45c4d96f6ea2f6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Process dataset\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    _json = examples[\"json\"]\n",
        "    texts = []\n",
        "    for sample_obj in _json:\n",
        "        # sample_obj = json.loads(sample[\"json\"])\n",
        "        text = get_formatted_sample(json.loads(sample_obj))\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"madroid/glaive-function-calling-openai\", split = \"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfao4tIBzOhi",
        "outputId": "215759e5-f5ce-4e37-d478-bb2f2f952eec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "\n",
            "Environment: ipython\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 23 July 2024\n",
            "\n",
            "# Tool Instructions\n",
            "- Always execute python code in messages that you share.\n",
            "- When looking for real time information use relevant functions if available else let the user know\n",
            "\n",
            "\n",
            "\n",
            "You have access to the following functions:\n",
            "\n",
            "Use the function 'track_calories' to: Track daily calorie intake\n",
            "{\"name\": \"track_calories\", \"description\": \"Track daily calorie intake\", \"parameters\": {\"meal\": {\"param_type\": \"string\", \"description\": \"The meal for which calories are being tracked\", \"required\": true}, \"calories\": {\"param_type\": \"int\", \"description\": \"The number of calories consumed\", \"required\": true}, \"date\": {\"param_type\": \"string\", \"description\": \"The date for which calories are being tracked\", \"required\": true}}}\n",
            "\n",
            "\n",
            "If a you choose to call a function ONLY reply in the following format:\n",
            "<{start_tag}={function_name}>{parameters}{end_tag}\n",
            "where\n",
            "\n",
            "start_tag => `<function`\n",
            "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
            "end_tag => `</function>`\n",
            "\n",
            "Here is an example,\n",
            "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
            "\n",
            "Reminder:\n",
            "- Function calls MUST follow the specified format\n",
            "- Required parameters MUST be specified\n",
            "- Only call one function at a time\n",
            "- Put the entire function call reply on one line\n",
            "- Always add your sources when using search results to answer the user query\n",
            "\n",
            "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Hi, I had a pizza for lunch today which was about 800 calories. Can you track this for me?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
            "\n",
            "<function=track_calories>{\"meal\": \"pizza\", \"calories\": 800, \"date\": \"2022-03-01\"}</function><|eom_id|><|start_header_id|>ipython<|end_header_id|>\n",
            "\n",
            "{\"status\": \"success\", \"message\": \"Calories for your pizza meal have been successfully tracked for the date 2022-03-01\"}<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
            "\n",
            "Great! The calories for your pizza meal have been successfully tracked for today.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "That's awesome! Can you also order a pizza for me from the nearest pizza place?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
            "\n",
            "I'm sorry, but as an AI, I don't have the capability to perform external tasks such as placing orders. My primary function is to assist you with the functions provided to me, such as tracking your calorie intake.<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "3237e04b476b4142ae8a0309dcdf327a",
            "8b94291cab6240c596621923a4bfc213",
            "6c3fb60f196a46799685f7cbbb0be28e",
            "c259833aa6d148749293cb0bd7849089",
            "a32b643a370d4c8faac31cb30aba28dd",
            "25cba0c7c3b64666879ea3157d4b43fb",
            "e5cf8fa8df7e458881e2fc468cc707e4",
            "fe67b32b5edd4808916aa9e63a8c8d9b",
            "7b5ba5b5da384cbcb422f945740a755d",
            "808f9973de6844b584dd53b630a398e5",
            "e1a68f9deb114c0e8da8229edf323926",
            "b5b51a206563427eac85fe849439b99f",
            "ba61fdc809444053969d58813a608d6d",
            "cc40514e343f4f559049b616b2eacc1f",
            "7db6511d4abe4e358ad04ae5ec166140",
            "e0785da126f547748282d18c4b79fd58",
            "19343326b2de49079565b8e64b67e031",
            "458d4fb43fd34a54bf4c6afb8dff2849",
            "74a06f38b6f54ce6a21ce43edc9f1641",
            "2e5ea29454bb462a9d2eaef3aaf4b186",
            "be011cc34c674ef9a237858b6ff8f728",
            "f3f34dd0896847fc9161d1a158f60f13",
            "3b063da052a44e7abfb00a1f52945e2a",
            "1e73832bd5ad4d808a719e446c78dec0",
            "5e25580d97b34fafa75f9b1dc3d1882f",
            "6e7c8c1e2c434f468eb2f412031d4f7c",
            "b9b6dc43ef474d3a972f2e4ee6852dca",
            "89d0ea94a2314c7a8a88943cf641a649",
            "04e79c7f06294ab8a8074e2e2916fa56",
            "2f17a530623049b59b1a5197e7f80370",
            "40915aa8e4e84dd7a58c0738e707fe1b",
            "3efc83359f7b4d99b70d6ab9fa25d23a",
            "91fa89bb400741b4a0fe046b1365dc42",
            "6cd1b567f37e479eb3d1cdab522dd39d",
            "4997c8e41a3e423a9b3ebe0081746931",
            "01825c2a354d40799555a990ba73996b",
            "8f2fd22e31f4485ba97f2fe38e61c9f0",
            "1921af3669174ac087763cdc506ee76d",
            "269f717369c64b90b7e80fbb9c1a9997",
            "4fb7436f92ee48cdac83c344904dcccf",
            "eb7a01cb8f3848eb94734efa0aee1e61",
            "4dc4406ad32e4abf8a491fb59006b491",
            "87334ad1ff3f4281977968469e37183d",
            "ea5cc23294cc474e93840332d604971a"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "3bfafb60-d7f4-45b5-9937-4b3d1d84bc14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Converting train dataset to ChatML (num_proc=2):   0%|          | 0/112754 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3237e04b476b4142ae8a0309dcdf327a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Applying chat template to train dataset (num_proc=2):   0%|          | 0/112754 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5b51a206563427eac85fe849439b99f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset (num_proc=2):   0%|          | 0/112754 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b063da052a44e7abfb00a1f52945e2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset (num_proc=2):   0%|          | 0/112754 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cd1b567f37e479eb3d1cdab522dd39d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "2ejIt2xSNKKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85db6ec0-4f15-4565-b9e3-ff39611c31ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "5.516 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yqxqAZ7KJ4oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "922eba74-3147-4c92-f120-eebd234abea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 112,754 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 60\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 20:26, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.022000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.147200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.373700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.681200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.539600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.761500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.689500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.524600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.107300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.122800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.948900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.939600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.820500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.788200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.609800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.652800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.639200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.374600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.437900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.420400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.449600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.460100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.490300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.400400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.287900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.439200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.502500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.201300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.442800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.377000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.598200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.460600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.201500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.437300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.341100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.322100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.595400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.289700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.415600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.298400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.492500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.508200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.188600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.425400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.261800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.506300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.411200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.165600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.544000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.265200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.476600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.308800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.237200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.361200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.309200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.375700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.369600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.333500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.573200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.230900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "pCqnaKmlO1U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e4f04c-5ade-4097-b775-5d6b27a6289a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1263.8918 seconds used for training.\n",
            "21.06 minutes used for training.\n",
            "Peak reserved memory = 7.467 GB.\n",
            "Peak reserved memory for training = 1.951 GB.\n",
            "Peak reserved memory % of max memory = 50.655 %.\n",
            "Peak reserved memory for training % of max memory = 13.235 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! We'll load the `test` split of our dataset and prepare it to generation.\n",
        "\n",
        "**[NOTE]** To use the model's tool calling capabilities in a more streamlined way you should use a scaffolding framework such as [llama-stack-apps](https://github.com/meta-llama/llama-stack-apps). For the scope of this demo we will test the model manually.\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = load_dataset(\"madroid/glaive-function-calling-openai\", split = \"test\")\n",
        "dataset_test = dataset_test.map(formatting_prompts_func, batched = True,)"
      ],
      "metadata": {
        "id": "5iUqU8oqg1Ij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3623ca82f6ef49c285ffde06c2265d47",
            "f12f63657f344aaaae37d0b926ef2a67",
            "174598c6bb8946bfb288980ecfb41043",
            "e57a6673a2b24f61a86952868d19398b",
            "03aa9cc5cce4488dbf4d82d62e72af16",
            "5c29f4e94b2647f3abadfacaa590e2bb",
            "70701b3922a84f0eaaa8eaffeb9787d3",
            "2c2099110ef84a89a8eac9b4ac02106a",
            "5c38cfd5e75f4ab98d1613f95fcf8733",
            "52a792e911f649b9b051ce1578832686",
            "2b09ff9587ab4ff5a07a8e46bb49b413"
          ]
        },
        "outputId": "0a0ab140-af55-4dbc-e2c1-b85e44e2eae9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/967 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3623ca82f6ef49c285ffde06c2265d47"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model determining which tool to call**\n",
        "\n",
        "We feed the model with the generation prompt. It responds with a tool call in the following format:\n",
        "\n",
        "```\n",
        "\n",
        "<function=example_function_name>{\"example_name\": \"example_value\"}</function><|eom_id|>\n",
        "```"
      ],
      "metadata": {
        "id": "ke46c6SptW9m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "d87f4648-2361-472f-9bab-3618bc8ed6ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "\n",
            "Environment: ipython\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 23 July 2024\n",
            "\n",
            "# Tool Instructions\n",
            "- Always execute python code in messages that you share.\n",
            "- When looking for real time information use relevant functions if available else let the user know\n",
            "\n",
            "\n",
            "\n",
            "You have access to the following functions:\n",
            "\n",
            "Use the function 'calculate_fuel_consumption' to: Calculate the fuel consumption based on distance and fuel efficiency\n",
            "{\"name\": \"calculate_fuel_consumption\", \"description\": \"Calculate the fuel consumption based on distance and fuel efficiency\", \"parameters\": {\"distance\": {\"param_type\": \"int\", \"description\": \"The distance traveled\", \"required\": true}, \"fuel_efficiency\": {\"param_type\": \"int\", \"description\": \"The fuel efficiency in kilometers per liter\", \"required\": true}}}\n",
            "\n",
            "\n",
            "If a you choose to call a function ONLY reply in the following format:\n",
            "<{start_tag}={function_name}>{parameters}{end_tag}\n",
            "where\n",
            "\n",
            "start_tag => `<function`\n",
            "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
            "end_tag => `</function>`\n",
            "\n",
            "Here is an example,\n",
            "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
            "\n",
            "Reminder:\n",
            "- Function calls MUST follow the specified format\n",
            "- Required parameters MUST be specified\n",
            "- Only call one function at a time\n",
            "- Put the entire function call reply on one line\n",
            "- Always add your sources when using search results to answer the user query\n",
            "\n",
            "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Hi, I need to calculate the fuel consumption for my car. I have traveled 500 kilometers and my car's fuel efficiency is 20 kilometers per liter. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
            "==============================\n",
            "                 \n",
            "\n",
            "<function=calculate_fuel_consumption>{\"distance\": 500, \"fuel_efficiency\": 20}</function><|eom_id|>\n"
          ]
        }
      ],
      "source": [
        "test_sample = dataset_test[128][\"text\"]\n",
        "\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "\n",
        "context = test_sample+assistant_continuation_prefix\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    context,\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "print(context)\n",
        "print(\"===\"*10)\n",
        "\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "output_text = tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "\n",
        "output_text = output_text[len(context):]\n",
        "print(output_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **User-defined Custom tools**\n",
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "# function to parse model's response\n",
        "def parse_function_call(s: str):\n",
        "    # Regex pattern to extract function name and JSON arguments\n",
        "    match = re.search(r\"<function=(\\w+)>(\\{.*?\\})</function>\", s)\n",
        "\n",
        "    if match:\n",
        "        function_name = match.group(1)  # Extract function name\n",
        "        args_json = match.group(2)      # Extract JSON string\n",
        "        args = json.loads(args_json)    # Parse JSON to dictionary\n",
        "        return function_name, args\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# CUSTOM TOOLS\n",
        "def calculate_loan_emi(loan_amount: int, interest_rate: int, loan_term: int) -> float:\n",
        "    monthly_interest_rate = (interest_rate / 100) / 12\n",
        "\n",
        "    if monthly_interest_rate == 0:\n",
        "        emi = loan_amount / loan_term\n",
        "    else:\n",
        "        emi = (loan_amount * monthly_interest_rate * (1 + monthly_interest_rate) ** loan_term) / \\\n",
        "              ((1 + monthly_interest_rate) ** loan_term - 1)\n",
        "\n",
        "    return round(emi, 2)\n",
        "\n",
        "\n",
        "def calculate_fuel_consumption(distance: int, fuel_efficiency: int) -> float:\n",
        "    if fuel_efficiency <= 0:\n",
        "        raise ValueError(\"Fuel efficiency must be greater than zero.\")\n",
        "\n",
        "    fuel_consumed = distance / fuel_efficiency\n",
        "    return round(fuel_consumed, 2)\n",
        "\n",
        "\n",
        "TOOLS = {\n",
        "    \"calculate_loan_emi\": calculate_loan_emi,\n",
        "    \"calculate_fuel_consumption\": calculate_fuel_consumption,\n",
        "}"
      ],
      "metadata": {
        "id": "ln4cwSVJqLjh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result from calling the tool is passed back to the model and it generates the final response the user**\n",
        "\n",
        "Now we add the tool call from the previous generation and its result to the context, the model then generates the final response."
      ],
      "metadata": {
        "id": "sFiDaiRPuOzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse and execute tool given model output\n",
        "function_name, arguments = parse_function_call(output_text)\n",
        "\n",
        "\n",
        "if function_name is not None:\n",
        "  tool_response = TOOLS[function_name](**arguments)\n",
        "\n",
        "  # Prepare context\n",
        "  context = test_sample # original input\n",
        "  # Add tool call and response\n",
        "  context += assistant_tool_message.format(output_text)\n",
        "  context += tool_response_message.format(tool_response)\n",
        "  # Add generation prompt\n",
        "  context += assistant_continuation_prefix\n",
        "\n",
        "  FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "  inputs = tokenizer(\n",
        "  [\n",
        "      context\n",
        "  ], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "  print(context)\n",
        "  print(\"===\"*20)\n",
        "\n",
        "  outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "\n",
        "  output_text_chat = tokenizer.batch_decode(outputs)\n",
        "  output_text_chat = output_text_chat[0][len(context):]\n",
        "  print(output_text_chat)"
      ],
      "metadata": {
        "id": "Ww_lGt0_uj82",
        "outputId": "0b8d80ea-d017-493f-9509-e62804d8e71d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "\n",
            "Environment: ipython\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 23 July 2024\n",
            "\n",
            "# Tool Instructions\n",
            "- Always execute python code in messages that you share.\n",
            "- When looking for real time information use relevant functions if available else let the user know\n",
            "\n",
            "\n",
            "\n",
            "You have access to the following functions:\n",
            "\n",
            "Use the function 'calculate_fuel_consumption' to: Calculate the fuel consumption based on distance and fuel efficiency\n",
            "{\"name\": \"calculate_fuel_consumption\", \"description\": \"Calculate the fuel consumption based on distance and fuel efficiency\", \"parameters\": {\"distance\": {\"param_type\": \"int\", \"description\": \"The distance traveled\", \"required\": true}, \"fuel_efficiency\": {\"param_type\": \"int\", \"description\": \"The fuel efficiency in kilometers per liter\", \"required\": true}}}\n",
            "\n",
            "\n",
            "If a you choose to call a function ONLY reply in the following format:\n",
            "<{start_tag}={function_name}>{parameters}{end_tag}\n",
            "where\n",
            "\n",
            "start_tag => `<function`\n",
            "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
            "end_tag => `</function>`\n",
            "\n",
            "Here is an example,\n",
            "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
            "\n",
            "Reminder:\n",
            "- Function calls MUST follow the specified format\n",
            "- Required parameters MUST be specified\n",
            "- Only call one function at a time\n",
            "- Put the entire function call reply on one line\n",
            "- Always add your sources when using search results to answer the user query\n",
            "\n",
            "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Hi, I need to calculate the fuel consumption for my car. I have traveled 500 kilometers and my car's fuel efficiency is 20 kilometers per liter. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
            "\n",
            "                 \n",
            "\n",
            "<function=calculate_fuel_consumption>{\"distance\": 500, \"fuel_efficiency\": 20}</function><|eom_id|><|eom_id|><|start_header_id|>ipython<|end_header_id|>\n",
            "\n",
            "25.0<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
            "============================================================\n",
            "                 \n",
            "\n",
            "The fuel consumption for your car would be 25.0 liters.<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2pEuRb1r2Vg",
        "outputId": "6a7c4e8a-3015-4026-d5f2-bf131c5b4953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "\n",
            "Environment: ipython\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 23 July 2024\n",
            "\n",
            "# Tool Instructions\n",
            "- Always execute python code in messages that you share.\n",
            "- When looking for real time information use relevant functions if available else let the user know\n",
            "\n",
            "\n",
            "\n",
            "You have access to the following functions:\n",
            "\n",
            "Use the function 'calculate_fuel_consumption' to: Calculate the fuel consumption based on distance and fuel efficiency\n",
            "{\"name\": \"calculate_fuel_consumption\", \"description\": \"Calculate the fuel consumption based on distance and fuel efficiency\", \"parameters\": {\"distance\": {\"param_type\": \"int\", \"description\": \"The distance traveled\", \"required\": true}, \"fuel_efficiency\": {\"param_type\": \"int\", \"description\": \"The fuel efficiency in kilometers per liter\", \"required\": true}}}\n",
            "\n",
            "\n",
            "If a you choose to call a function ONLY reply in the following format:\n",
            "<{start_tag}={function_name}>{parameters}{end_tag}\n",
            "where\n",
            "\n",
            "start_tag => `<function`\n",
            "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
            "end_tag => `</function>`\n",
            "\n",
            "Here is an example,\n",
            "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
            "\n",
            "Reminder:\n",
            "- Function calls MUST follow the specified format\n",
            "- Required parameters MUST be specified\n",
            "- Only call one function at a time\n",
            "- Put the entire function call reply on one line\n",
            "- Always add your sources when using search results to answer the user query\n",
            "\n",
            "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Hi, I need to calculate the fuel consumption for my car. I have traveled 500 kilometers and my car's fuel efficiency is 20 kilometers per liter. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
            "\n",
            "<function=calculate_fuel_consumption>{\"distance\": 500, \"fuel_efficiency\": 20}</function><|eom_id|>\n"
          ]
        }
      ],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    test_sample+assistant_continuation_prefix,\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "973e4561-f354-4595-eaf9-1a0f7f18fc4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX_XKs_BNZR",
        "outputId": "4297ecc7-fac6-4c8e-8e50-6f5887fc9ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "\n",
            "Environment: ipython\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 23 July 2024\n",
            "\n",
            "# Tool Instructions\n",
            "- Always execute python code in messages that you share.\n",
            "- When looking for real time information use relevant functions if available else let the user know\n",
            "\n",
            "\n",
            "\n",
            "You have access to the following functions:\n",
            "\n",
            "Use the function 'calculate_fuel_consumption' to: Calculate the fuel consumption based on distance and fuel efficiency\n",
            "{\"name\": \"calculate_fuel_consumption\", \"description\": \"Calculate the fuel consumption based on distance and fuel efficiency\", \"parameters\": {\"distance\": {\"param_type\": \"int\", \"description\": \"The distance traveled\", \"required\": true}, \"fuel_efficiency\": {\"param_type\": \"int\", \"description\": \"The fuel efficiency in kilometers per liter\", \"required\": true}}}\n",
            "\n",
            "\n",
            "If a you choose to call a function ONLY reply in the following format:\n",
            "<{start_tag}={function_name}>{parameters}{end_tag}\n",
            "where\n",
            "\n",
            "start_tag => `<function`\n",
            "parameters => a JSON dict with the function argument name as key and function argument value as value.\n",
            "end_tag => `</function>`\n",
            "\n",
            "Here is an example,\n",
            "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
            "\n",
            "Reminder:\n",
            "- Function calls MUST follow the specified format\n",
            "- Required parameters MUST be specified\n",
            "- Only call one function at a time\n",
            "- Put the entire function call reply on one line\n",
            "- Always add your sources when using search results to answer the user query\n",
            "\n",
            "You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Hi, I need to calculate the fuel consumption for my car. I have traveled 500 kilometers and my car's fuel efficiency is 20 kilometers per liter. Can you help me with that?<|eot_id|><|start_header_id|>assistant<|end_header_id|>                      \n",
            "==============================\n",
            "                 \n",
            "\n",
            "<function=calculate_fuel_consumption>{\"distance\": 500, \"fuel_efficiency\": 20}</function><|eom_id|>\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "test_sample = dataset_test[128][\"text\"]\n",
        "context = test_sample+assistant_continuation_prefix\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    context,\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "print(context)\n",
        "print(\"===\"*10)\n",
        "\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "output_text = tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "\n",
        "output_text = output_text[len(context):]\n",
        "print(output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh6A70Xzjn4Z"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Llama 3.2 Conversational notebook. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a260c69c1bc24faaba45c4d96f6ea2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ed1d73212784ebf81c2496cff7e1f2a",
              "IPY_MODEL_53565e6b78004ef9b447121f84985bb7",
              "IPY_MODEL_86edadf55c99416e911ad55d52494038"
            ],
            "layout": "IPY_MODEL_819ba37f02e549b3bd4b3b7b87f56d1f"
          }
        },
        "3ed1d73212784ebf81c2496cff7e1f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea72b5a4fcc54096870d16e6ecb0ca3a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7f7aeb38c44a4732af38180fcfb1da6c",
            "value": "Map:‚Äá100%"
          }
        },
        "53565e6b78004ef9b447121f84985bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c607cb289d05404386be3c5c87d83836",
            "max": 112754,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5f08b69b7e4432e9d983ac974e09b38",
            "value": 112754
          }
        },
        "86edadf55c99416e911ad55d52494038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b727b7e5455450d94724eec947e3004",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_848e8392e481410badcdccd57d13dee7",
            "value": "‚Äá112754/112754‚Äá[00:23&lt;00:00,‚Äá3700.54‚Äáexamples/s]"
          }
        },
        "819ba37f02e549b3bd4b3b7b87f56d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea72b5a4fcc54096870d16e6ecb0ca3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f7aeb38c44a4732af38180fcfb1da6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c607cb289d05404386be3c5c87d83836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5f08b69b7e4432e9d983ac974e09b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b727b7e5455450d94724eec947e3004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "848e8392e481410badcdccd57d13dee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3237e04b476b4142ae8a0309dcdf327a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b94291cab6240c596621923a4bfc213",
              "IPY_MODEL_6c3fb60f196a46799685f7cbbb0be28e",
              "IPY_MODEL_c259833aa6d148749293cb0bd7849089"
            ],
            "layout": "IPY_MODEL_a32b643a370d4c8faac31cb30aba28dd"
          }
        },
        "8b94291cab6240c596621923a4bfc213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25cba0c7c3b64666879ea3157d4b43fb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e5cf8fa8df7e458881e2fc468cc707e4",
            "value": "Converting‚Äátrain‚Äádataset‚Äáto‚ÄáChatML‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "6c3fb60f196a46799685f7cbbb0be28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe67b32b5edd4808916aa9e63a8c8d9b",
            "max": 112754,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b5ba5b5da384cbcb422f945740a755d",
            "value": 112754
          }
        },
        "c259833aa6d148749293cb0bd7849089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808f9973de6844b584dd53b630a398e5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e1a68f9deb114c0e8da8229edf323926",
            "value": "‚Äá112754/112754‚Äá[00:10&lt;00:00,‚Äá17409.56‚Äáexamples/s]"
          }
        },
        "a32b643a370d4c8faac31cb30aba28dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25cba0c7c3b64666879ea3157d4b43fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5cf8fa8df7e458881e2fc468cc707e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe67b32b5edd4808916aa9e63a8c8d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b5ba5b5da384cbcb422f945740a755d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "808f9973de6844b584dd53b630a398e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a68f9deb114c0e8da8229edf323926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5b51a206563427eac85fe849439b99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba61fdc809444053969d58813a608d6d",
              "IPY_MODEL_cc40514e343f4f559049b616b2eacc1f",
              "IPY_MODEL_7db6511d4abe4e358ad04ae5ec166140"
            ],
            "layout": "IPY_MODEL_e0785da126f547748282d18c4b79fd58"
          }
        },
        "ba61fdc809444053969d58813a608d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19343326b2de49079565b8e64b67e031",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_458d4fb43fd34a54bf4c6afb8dff2849",
            "value": "Applying‚Äáchat‚Äátemplate‚Äáto‚Äátrain‚Äádataset‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "cc40514e343f4f559049b616b2eacc1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a06f38b6f54ce6a21ce43edc9f1641",
            "max": 112754,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e5ea29454bb462a9d2eaef3aaf4b186",
            "value": 112754
          }
        },
        "7db6511d4abe4e358ad04ae5ec166140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be011cc34c674ef9a237858b6ff8f728",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f3f34dd0896847fc9161d1a158f60f13",
            "value": "‚Äá112754/112754‚Äá[00:09&lt;00:00,‚Äá18986.40‚Äáexamples/s]"
          }
        },
        "e0785da126f547748282d18c4b79fd58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19343326b2de49079565b8e64b67e031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "458d4fb43fd34a54bf4c6afb8dff2849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74a06f38b6f54ce6a21ce43edc9f1641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e5ea29454bb462a9d2eaef3aaf4b186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be011cc34c674ef9a237858b6ff8f728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f34dd0896847fc9161d1a158f60f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b063da052a44e7abfb00a1f52945e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e73832bd5ad4d808a719e446c78dec0",
              "IPY_MODEL_5e25580d97b34fafa75f9b1dc3d1882f",
              "IPY_MODEL_6e7c8c1e2c434f468eb2f412031d4f7c"
            ],
            "layout": "IPY_MODEL_b9b6dc43ef474d3a972f2e4ee6852dca"
          }
        },
        "1e73832bd5ad4d808a719e446c78dec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89d0ea94a2314c7a8a88943cf641a649",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_04e79c7f06294ab8a8074e2e2916fa56",
            "value": "Tokenizing‚Äátrain‚Äádataset‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "5e25580d97b34fafa75f9b1dc3d1882f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f17a530623049b59b1a5197e7f80370",
            "max": 112754,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40915aa8e4e84dd7a58c0738e707fe1b",
            "value": 112754
          }
        },
        "6e7c8c1e2c434f468eb2f412031d4f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3efc83359f7b4d99b70d6ab9fa25d23a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_91fa89bb400741b4a0fe046b1365dc42",
            "value": "‚Äá112754/112754‚Äá[03:52&lt;00:00,‚Äá584.47‚Äáexamples/s]"
          }
        },
        "b9b6dc43ef474d3a972f2e4ee6852dca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d0ea94a2314c7a8a88943cf641a649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04e79c7f06294ab8a8074e2e2916fa56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f17a530623049b59b1a5197e7f80370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40915aa8e4e84dd7a58c0738e707fe1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3efc83359f7b4d99b70d6ab9fa25d23a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91fa89bb400741b4a0fe046b1365dc42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cd1b567f37e479eb3d1cdab522dd39d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4997c8e41a3e423a9b3ebe0081746931",
              "IPY_MODEL_01825c2a354d40799555a990ba73996b",
              "IPY_MODEL_8f2fd22e31f4485ba97f2fe38e61c9f0"
            ],
            "layout": "IPY_MODEL_1921af3669174ac087763cdc506ee76d"
          }
        },
        "4997c8e41a3e423a9b3ebe0081746931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_269f717369c64b90b7e80fbb9c1a9997",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4fb7436f92ee48cdac83c344904dcccf",
            "value": "Truncating‚Äátrain‚Äádataset‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "01825c2a354d40799555a990ba73996b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb7a01cb8f3848eb94734efa0aee1e61",
            "max": 112754,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dc4406ad32e4abf8a491fb59006b491",
            "value": 112754
          }
        },
        "8f2fd22e31f4485ba97f2fe38e61c9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87334ad1ff3f4281977968469e37183d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ea5cc23294cc474e93840332d604971a",
            "value": "‚Äá112754/112754‚Äá[01:39&lt;00:00,‚Äá1243.39‚Äáexamples/s]"
          }
        },
        "1921af3669174ac087763cdc506ee76d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "269f717369c64b90b7e80fbb9c1a9997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb7436f92ee48cdac83c344904dcccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb7a01cb8f3848eb94734efa0aee1e61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dc4406ad32e4abf8a491fb59006b491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87334ad1ff3f4281977968469e37183d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea5cc23294cc474e93840332d604971a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3623ca82f6ef49c285ffde06c2265d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f12f63657f344aaaae37d0b926ef2a67",
              "IPY_MODEL_174598c6bb8946bfb288980ecfb41043",
              "IPY_MODEL_e57a6673a2b24f61a86952868d19398b"
            ],
            "layout": "IPY_MODEL_03aa9cc5cce4488dbf4d82d62e72af16"
          }
        },
        "f12f63657f344aaaae37d0b926ef2a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c29f4e94b2647f3abadfacaa590e2bb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_70701b3922a84f0eaaa8eaffeb9787d3",
            "value": "Map:‚Äá100%"
          }
        },
        "174598c6bb8946bfb288980ecfb41043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c2099110ef84a89a8eac9b4ac02106a",
            "max": 967,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c38cfd5e75f4ab98d1613f95fcf8733",
            "value": 967
          }
        },
        "e57a6673a2b24f61a86952868d19398b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52a792e911f649b9b051ce1578832686",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2b09ff9587ab4ff5a07a8e46bb49b413",
            "value": "‚Äá967/967‚Äá[00:00&lt;00:00,‚Äá17313.12‚Äáexamples/s]"
          }
        },
        "03aa9cc5cce4488dbf4d82d62e72af16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c29f4e94b2647f3abadfacaa590e2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70701b3922a84f0eaaa8eaffeb9787d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c2099110ef84a89a8eac9b4ac02106a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c38cfd5e75f4ab98d1613f95fcf8733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52a792e911f649b9b051ce1578832686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b09ff9587ab4ff5a07a8e46bb49b413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}